{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine data from chapter 4, and create a new model with the appropriate number of input parameters\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_path=\"./winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " tensor([6., 6., 6.,  ..., 6., 7., 6.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path))) #next item from the iterator\n",
    "num_row = wineq_numpy.shape[0]\n",
    "num_col = wineq_numpy.shape[1]\n",
    "attrs = torch.tensor(np.array(wineq_numpy[:,0:11]))\n",
    "ans = torch.tensor(np.array(wineq_numpy[:,11]))\n",
    "attrs, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 20,\n",
       " 4: 163,\n",
       " 5: 1457,\n",
       " 6: 2198,\n",
       " 7: 880,\n",
       " 8: 175,\n",
       " 9: 5,\n",
       " 10: 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality = {0:0,1:0,2:0, 3:0, 4:0, 5:0, 6:0,7:0,8:0,9:0,10:0}\n",
    "for a in ans:\n",
    "    quality[a.item()]+=1\n",
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_devide_set(t_u: torch, t_c:torch, ratio):\n",
    "    n_samples = t_u.shape[0]\n",
    "    n_val = int(ratio*n_samples)\n",
    "\n",
    "    shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "    train_indices = shuffled_indices[:-n_val]\n",
    "    val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "    train_indices, val_indices\n",
    "    train_t_u = t_u[train_indices]\n",
    "    train_t_c = t_c [train_indices]\n",
    "\n",
    "    val_t_u = t_u[val_indices]\n",
    "    val_t_c = t_c [val_indices]\n",
    "\n",
    "    return train_t_u, train_t_c, val_t_u, val_t_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3919, 11]) torch.Size([979, 11])\n",
      "torch.Size([3919, 1]) torch.Size([979, 1])\n",
      "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
      "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])\n",
      "tensor([0.6855, 0.2782, 0.3342, 0.6391, 0.0458, 0.3531, 1.3836, 0.0994, 0.3188,\n",
      "        0.4898, 1.0514])\n"
     ]
    }
   ],
   "source": [
    "col_norm1 = [True,False,False,True,False,False,False,True,True,False,True]\n",
    "col_norm2 = [False,False,False,False,False,True,True,False,False,False,False]\n",
    "attrs_n = attrs.clone()\n",
    "attrs_n[:,col_norm1] *= 0.1\n",
    "attrs_n[:,col_norm2] *= 0.01\n",
    "ans_n = ans*0.1\n",
    "attr_t, ans_t, attr_v, ans_v = shuffle_and_devide_set(attrs_n, ans_n, 0.2)\n",
    "ans_t = ans_t.unsqueeze(1);\n",
    "ans_v = ans_v.unsqueeze(1);\n",
    "\n",
    "print(attr_t.shape, attr_v.shape)\n",
    "print(ans_t.shape, ans_v.shape)\n",
    "print(attrs.mean(dim=0))\n",
    "print( attrs_n.mean(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_out_ans(output:torch, ans:torch) :\n",
    "    r_out = torch.round(output.squeeze()*10)\n",
    "    ans = ans.squeeze()*10\n",
    "    total=0\n",
    "    right=0\n",
    "    length = output.shape[0]\n",
    "    for i in range(0,length):\n",
    "        total+=1\n",
    "        if(r_out[i] == ans[i]):\n",
    "            right+=1\n",
    "    return right, total\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs:int, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train=loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_p_val = model(t_u_val)\n",
    "            loss_val = loss_fn(t_p_val, t_c_val)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch <=3 or epoch % 500 == 0:\n",
    "            right, total = compare_out_ans(t_p_val, t_c_val) \n",
    "            print(f\"Epoch {epoch:5d}, Train Loss {loss_train.item():.4f}, val loss {loss_val.item():.4f}\",\n",
    "            f\"    score: {right} / {total} = {right/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     1, Train Loss 0.2428, val loss 0.2396     score: 0 / 979 = 0.00%\n",
      "Epoch     2, Train Loss 0.1664, val loss 0.1636     score: 2 / 979 = 0.20%\n",
      "Epoch     3, Train Loss 0.1065, val loss 0.1041     score: 5 / 979 = 0.51%\n",
      "Epoch   500, Train Loss 0.0056, val loss 0.0056     score: 512 / 979 = 52.30%\n",
      "Epoch  1000, Train Loss 0.0055, val loss 0.0055     score: 514 / 979 = 52.50%\n",
      "Epoch  1500, Train Loss 0.0054, val loss 0.0054     score: 510 / 979 = 52.09%\n",
      "Epoch  2000, Train Loss 0.0053, val loss 0.0053     score: 508 / 979 = 51.89%\n",
      "Epoch  2500, Train Loss 0.0053, val loss 0.0053     score: 512 / 979 = 52.30%\n",
      "Epoch  3000, Train Loss 0.0052, val loss 0.0053     score: 508 / 979 = 51.89%\n",
      "Epoch  3500, Train Loss 0.0052, val loss 0.0052     score: 516 / 979 = 52.71%\n",
      "Epoch  4000, Train Loss 0.0052, val loss 0.0052     score: 514 / 979 = 52.50%\n",
      "Epoch  4500, Train Loss 0.0053, val loss 0.0054     score: 491 / 979 = 50.15%\n",
      "Epoch  5000, Train Loss 0.0051, val loss 0.0052     score: 516 / 979 = 52.71%\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(11,11)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear', nn.Linear(11,6)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(6,1))\n",
    "       \n",
    "]))\n",
    "attr_t = attr_t.clone().detach().requires_grad_(True)\n",
    "attr_v = attr_v.clone().detach().requires_grad_(True)\n",
    "ans_t =  ans_t.clone().detach().requires_grad_(True)\n",
    "ans_v =  ans_v.clone().detach().requires_grad_(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr =1e-2)\n",
    "loss_fn = nn.MSELoss() \n",
    "training_loop(\n",
    "    5000, \n",
    "    optimizer, \n",
    "    model, \n",
    "    loss_fn, \n",
    "    attr_t, \n",
    "    attr_v,\n",
    "    ans_t, \n",
    "    ans_v\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 27.,   0., 184.,   0., 516.,   0., 236.,   0.,  14.,   2.]),\n",
       " array([-2. , -1.5, -1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = (model(attr_v)).detach().numpy()\n",
    "ans_v_numpy = ans_v.detach().numpy()\n",
    "ret = (out-ans_v_numpy)*10\n",
    "ret =np.round(ret)\n",
    "plt.hist(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "073421e87fd17c22a27d2f3fee98ef1fca5a2c350357a034bdf2d94dc9e5a0d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ai_class': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
