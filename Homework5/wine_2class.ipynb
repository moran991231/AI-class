{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(\"./winequality-white.csv\",delimiter=\";\")\n",
    "dataframe_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4898, 11), (4898, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    input_cols = list(dataframe.columns)[:-1]\n",
    "    output_cols=list(dataframe.columns)[-1:]\n",
    "    dataframe1 = dataframe_raw.copy(deep=True)\n",
    "    inputs_array = dataframe1[input_cols].to_numpy(dtype=np.float32)\n",
    "    targets_array = dataframe1[output_cols].to_numpy(dtype=int).squeeze(1)\n",
    "    targets_array[targets_array<=5]=0\n",
    "    targets_array[targets_array>5]=1   \n",
    "    print(targets_array)\n",
    "    encoding =np.eye(2)[targets_array]\n",
    "\n",
    "    return inputs_array, encoding\n",
    "inputs_array, targets_array = dataframe_to_arrays(dataframe_raw)\n",
    "inputs_array.shape, targets_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs_array)\n",
    "targets = torch.from_numpy(targets_array)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets )\n",
    "num_samples = inputs.shape[0]\n",
    "num_train = int(num_samples*0.8); num_val = num_samples-num_train\n",
    "train_ds, val_ds = random_split(dataset,[num_train,num_val])\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, loss_fn, n_epochs, train_loader, val_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            # inputs, labels = inputs, labels\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if(epoch<=2 or epoch%10==0):\n",
    "            correct=0;total=0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                    # inputs, labels = inputs , labels \n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs, dim=1)\n",
    "                    for label, p in zip(labels, predicted):\n",
    "                        if(int(label[int(p)])==1):\n",
    "                            correct+=1                    \n",
    "                    total+= labels.shape[0]\n",
    "            print(f\"Epoch: {epoch:4d} Loss: {float(loss):4f}  accuracy: {correct}/{total} = {100.0*correct/total:4.1f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 Loss: 0.790757  accuracy: 464/980 = 47.3%\n",
      "Epoch:    1 Loss: 0.773850  accuracy: 558/980 = 56.9%\n",
      "Epoch:    2 Loss: 0.741404  accuracy: 453/980 = 46.2%\n",
      "Epoch:   10 Loss: 0.607320  accuracy: 617/980 = 63.0%\n",
      "Epoch:   20 Loss: 0.541687  accuracy: 614/980 = 62.7%\n",
      "Epoch:   30 Loss: 0.560864  accuracy: 628/980 = 64.1%\n",
      "Epoch:   40 Loss: 0.554002  accuracy: 625/980 = 63.8%\n",
      "Epoch:   50 Loss: 0.562459  accuracy: 650/980 = 66.3%\n",
      "Epoch:   60 Loss: 0.556414  accuracy: 642/980 = 65.5%\n",
      "Epoch:   70 Loss: 0.628238  accuracy: 625/980 = 63.8%\n",
      "Epoch:   80 Loss: 0.510828  accuracy: 639/980 = 65.2%\n",
      "Epoch:   90 Loss: 0.466213  accuracy: 631/980 = 64.4%\n",
      "Epoch:  100 Loss: 0.496366  accuracy: 632/980 = 64.5%\n",
      "Epoch:  110 Loss: 0.456326  accuracy: 648/980 = 66.1%\n",
      "Epoch:  120 Loss: 0.584667  accuracy: 648/980 = 66.1%\n",
      "Epoch:  130 Loss: 0.469737  accuracy: 654/980 = 66.7%\n",
      "Epoch:  140 Loss: 0.594329  accuracy: 665/980 = 67.9%\n",
      "Epoch:  150 Loss: 0.495311  accuracy: 668/980 = 68.2%\n",
      "Epoch:  160 Loss: 0.509183  accuracy: 652/980 = 66.5%\n",
      "Epoch:  170 Loss: 0.512904  accuracy: 656/980 = 66.9%\n",
      "Epoch:  180 Loss: 0.595166  accuracy: 660/980 = 67.3%\n",
      "Epoch:  190 Loss: 0.636277  accuracy: 670/980 = 68.4%\n",
      "Epoch:  200 Loss: 0.579527  accuracy: 662/980 = 67.6%\n",
      "Epoch:  210 Loss: 0.563679  accuracy: 686/980 = 70.0%\n",
      "Epoch:  220 Loss: 0.543777  accuracy: 688/980 = 70.2%\n",
      "Epoch:  230 Loss: 0.606215  accuracy: 685/980 = 69.9%\n",
      "Epoch:  240 Loss: 0.501179  accuracy: 688/980 = 70.2%\n",
      "Epoch:  250 Loss: 0.487705  accuracy: 684/980 = 69.8%\n",
      "Epoch:  260 Loss: 0.475471  accuracy: 686/980 = 70.0%\n",
      "Epoch:  270 Loss: 0.526025  accuracy: 656/980 = 66.9%\n",
      "Epoch:  280 Loss: 0.589942  accuracy: 666/980 = 68.0%\n",
      "Epoch:  290 Loss: 0.556168  accuracy: 641/980 = 65.4%\n",
      "Epoch:  300 Loss: 0.457228  accuracy: 671/980 = 68.5%\n",
      "Epoch:  310 Loss: 0.487680  accuracy: 690/980 = 70.4%\n",
      "Epoch:  320 Loss: 0.479562  accuracy: 668/980 = 68.2%\n",
      "Epoch:  330 Loss: 0.561574  accuracy: 695/980 = 70.9%\n",
      "Epoch:  340 Loss: 0.457495  accuracy: 665/980 = 67.9%\n",
      "Epoch:  350 Loss: 0.423033  accuracy: 673/980 = 68.7%\n",
      "Epoch:  360 Loss: 0.514075  accuracy: 686/980 = 70.0%\n",
      "Epoch:  370 Loss: 0.454414  accuracy: 693/980 = 70.7%\n",
      "Epoch:  380 Loss: 0.430993  accuracy: 690/980 = 70.4%\n",
      "Epoch:  390 Loss: 0.523479  accuracy: 696/980 = 71.0%\n",
      "Epoch:  400 Loss: 0.536636  accuracy: 669/980 = 68.3%\n",
      "Epoch:  410 Loss: 0.444009  accuracy: 684/980 = 69.8%\n",
      "Epoch:  420 Loss: 0.474145  accuracy: 699/980 = 71.3%\n",
      "Epoch:  430 Loss: 0.508904  accuracy: 700/980 = 71.4%\n",
      "Epoch:  440 Loss: 0.518129  accuracy: 693/980 = 70.7%\n",
      "Epoch:  450 Loss: 0.454065  accuracy: 681/980 = 69.5%\n",
      "Epoch:  460 Loss: 0.519678  accuracy: 704/980 = 71.8%\n",
      "Epoch:  470 Loss: 0.390497  accuracy: 704/980 = 71.8%\n",
      "Epoch:  480 Loss: 0.546526  accuracy: 706/980 = 72.0%\n",
      "Epoch:  490 Loss: 0.479912  accuracy: 703/980 = 71.7%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11,64), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(64,64), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,2)\n",
    ").to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "training_loop(model, optimizer, loss_fn,500, train_loader, val_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pkm294.tistory.com/45?category=997016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.393201  accuracy: 749/980 = 76.4%\n",
      "Epoch: 1 Loss: 0.412156  accuracy: 761/980 = 77.7%\n",
      "Epoch: 2 Loss: 0.319431  accuracy: 757/980 = 77.2%\n",
      "Epoch: 100 Loss: 0.434837  accuracy: 756/980 = 77.1%\n",
      "Epoch: 200 Loss: 0.503171  accuracy: 751/980 = 76.6%\n",
      "Epoch: 300 Loss: 0.440710  accuracy: 756/980 = 77.1%\n",
      "Epoch: 400 Loss: 0.448246  accuracy: 759/980 = 77.4%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1e-4)\n",
    "training_loop(model, optimizer, loss_fn,500, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "073421e87fd17c22a27d2f3fee98ef1fca5a2c350357a034bdf2d94dc9e5a0d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ai_class': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
